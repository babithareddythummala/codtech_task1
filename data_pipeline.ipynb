{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBQsCxdPuKf3",
        "outputId": "bb013195-adc3-4a6f-ce49-a918df1bb01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Extract Data (Load CSV)\n",
        "def extract_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Step 2: Handle Missing Values\n",
        "def handle_missing_values(df):\n",
        "    imputer = SimpleImputer(strategy=\"mean\")  # Fill missing numerical values with mean\n",
        "    df[df.select_dtypes(include=['number']).columns] = imputer.fit_transform(df.select_dtypes(include=['number']))\n",
        "    return df\n",
        "\n",
        "# Step 3: Encode Categorical Data\n",
        "def encode_categorical(df):\n",
        "    encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "    encoded_data = encoder.fit_transform(df[categorical_cols])\n",
        "    encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "    # Drop original categorical columns and concatenate encoded data\n",
        "    df = df.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "    df = pd.concat([df, encoded_df], axis=1)\n",
        "    return df\n",
        "\n",
        "# Step 4: Scale Numerical Data\n",
        "def scale_numerical_data(df):\n",
        "    scaler = StandardScaler()\n",
        "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
        "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "    return df\n",
        "\n",
        "# Step 5: Split Data into Training and Testing\n",
        "def split_data(df, target_column, test_size=0.2):\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Step 6: Load Data (Save Processed Data)\n",
        "def load_data(X_train, X_test, y_train, y_test):\n",
        "    X_train.to_csv(\"X_train.csv\", index=False)\n",
        "    X_test.to_csv(\"X_test.csv\", index=False)\n",
        "    y_train.to_csv(\"y_train.csv\", index=False)\n",
        "    y_test.to_csv(\"y_test.csv\", index=False)\n",
        "    print(\"Data successfully saved!\")\n",
        "\n",
        "# Pipeline Execution\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"heart.csv\"  # Update this with your dataset path\n",
        "    target_column = \"target\"  # Replace with actual target column name\n",
        "\n",
        "    df = extract_data(file_path)\n",
        "    df = handle_missing_values(df)\n",
        "    df = encode_categorical(df)\n",
        "    df = scale_numerical_data(df)\n",
        "    X_train, X_test, y_train, y_test = split_data(df, target_column)\n",
        "    load_data(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULFsoe6duoPS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}